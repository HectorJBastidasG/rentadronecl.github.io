<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Detection Models · Rentadrone.cl</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="Deep learning application for fault detection in photovoltaic plants. Trained detection models that point out where the panel faults are by using radiometric thermal infrared pictures, as well as a tutorial on how to use these algorithms in your own thermal photos. It also shows a step by step to train these models with its own database, in order to properly adjust the model to its particularity."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Detection Models · Rentadrone.cl"/><meta property="og:type" content="website"/><meta property="og:url" content="https://rentadronecl.github.io/"/><meta property="og:description" content="Deep learning application for fault detection in photovoltaic plants. Trained detection models that point out where the panel faults are by using radiometric thermal infrared pictures, as well as a tutorial on how to use these algorithms in your own thermal photos. It also shows a step by step to train these models with its own database, in order to properly adjust the model to its particularity."/><meta property="og:image" content="https://rentadronecl.github.io/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://rentadronecl.github.io/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/img/favicon.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/helices.png" alt="Rentadrone.cl"/><h2 class="headerTitleWithLogo">Rentadrone.cl</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/docs/developers" target="_self">Docs</a></li><li class=""><a href="/help" target="_self">Help</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Detection Models</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Developers</h3><ul class=""><li class="navListItem"><a class="navItem" href="/docs/developers">Developers</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Detection Models</h3><ul class=""><li class="navListItem navListItemActive"><a class="navItem" href="/docs/detection_models">Models</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Models Deployment</h3><ul class=""><li class="navListItem"><a class="navItem" href="/docs/deployment">Models Deployment</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Contributing Guidelines</h3><ul class=""><li class="navListItem"><a class="navItem" href="/docs/contributing">Contributing guidelines</a></li></ul></div><div class="navGroup"><h3 class="navGroupCategoryTitle">Code of Conduct</h3><ul class=""><li class="navListItem"><a class="navItem" href="/docs/code_of_conduct">Code of Conduct</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 id="__docusaurus" class="postHeaderTitle">Detection Models</h1></header><article><div><span><p>Deep learning application for fault detection in photovoltaic plants. Trained detection models that point out where the panel faults are by using radiometric thermal infrared pictures, as well as a tutorial on how to use these algorithms in your own thermal photos. It also shows a step by step to train these models with its own database, in order to properly adjust the model to its particularity.</p>
<h2><a class="anchor" aria-hidden="true" id="quickstart"></a><a href="#quickstart" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Quickstart</h2>
<p>In the root project execute the following command to install all dependencies project</p>
<pre><code class="hljs css language-bash">pip install -r requirements.txt
</code></pre>
<p>You need install Jupyter notebook to see the code example. You can find the installation documentation for the <a href="https://jupyter.readthedocs.io/en/latest/install.html">Jupyter platform, on ReadTheDocs</a> or in github page <a href="https://github.com/jupyter/notebook">here</a>.</p>
<p>For a local installation, make sure you have pip installed and run:</p>
<pre><code class="hljs css language-bash">pip install notebook
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="example-to-use-trained-model"></a><a href="#example-to-use-trained-model" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Example to use trained model</h3>
<p>In <a href="https://github.com/RentadroneCL/model-definition/blob/master/Example_prediction.ipynb">'Example_Prediction'</a> this is the example of how to implement an already trained model, it can be modified to change the model you have to use and the image in which you want to detect faults.</p>
<p>In <a href="https://github.com/RentadroneCL/model-definition/blob/master/Example%20Detection%20AllInOne.ipynb">'Example Prediction AllInOne'</a> this is the example of how implement all trained model, you can use this code for predict a folder of images and have a output image with detection boxes.</p>
<p>In <a href="https://github.com/RentadroneCL/model-definition/blob/master/Example_prediction_Ortofoto.ipynb">'Example_Prediction_Orthophoto'</a> this is the example of how implement all trained model, you can use this code for predict a Orthophot and have a output image with detection boxes.</p>
<h3><a class="anchor" aria-hidden="true" id="model-detection"></a><a href="#model-detection" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Model Detection</h3>
<p>The models used for detection are SSD <a href="https://arxiv.org/abs/1512.02325">SSD: Single Shot MultiBox Detector</a> and YOLOv3 [YOLOv3: An Incremental Improvement] (<a href="https://arxiv.org/abs/1804.02767">https://arxiv.org/abs/1804.02767</a>), they are imported from the following repositories:</p>
<ul>
<li><a href="https://github.com/pierluigiferrari/ssd_keras#how-to-fine-tune-one-of-the-trained-models-on-your-own-dataset">SSD_Keras</a></li>
<li><a href="https://github.com/experiencor/keras-yolo3">YOLOv3_Keras</a></li>
</ul>
<p>Grab the pretrained weights of SSD and  YOLO3 from <a href="https://drive.google.com/drive/folders/1LSc9FkAwJrAAT8pAUWz8aax_biFAMMXS?usp=sharing">Drive_Weights</a></p>
<table>
<thead>
<tr><th style="text-align:center">Model</th><th style="text-align:center">Pretrained Weights</th></tr>
</thead>
<tbody>
<tr><td style="text-align:center">SSD7/SSD300</td><td style="text-align:center"><a href="https://drive.google.com/open?id=1VHTx28tGI94yFqwT_WHp-xkx_8Hh_A31">Weight VGG16</a></td></tr>
<tr><td style="text-align:center">YOLO3</td><td style="text-align:center"><a href="https://drive.google.com/open?id=1cnCQHl-TnOrwb-leug1I0O9vMBaSwJLt">Weight Full Yolo3</a></td></tr>
</tbody>
</table>
<h3><a class="anchor" aria-hidden="true" id="type-of-data"></a><a href="#type-of-data" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Type of Data</h3>
<p>The images used for the design of this model were extracted by air analysis, specifically: FLIR aerial radiometric thermal infrared pictures, taken by UAV (R-JPEG format). Which were converted into .jpg images for the training of these detection models.
Example FLIR image:</p>
<p><img src="https://github.com/RentadroneCL/model-definition/raw/master/images/example_flir.jpg" alt="FLIR"></p>
<p>Same image in .jpg format:</p>
<p><img src="https://github.com/RentadroneCL/model-definition/raw/master/images/example.jpg" alt="JPG"></p>
<h3><a class="anchor" aria-hidden="true" id="training"></a><a href="#training" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Training</h3>
<h4><a class="anchor" aria-hidden="true" id="1-data-preparation"></a><a href="#1-data-preparation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>1. Data preparation</h4>
<p>View folder Train&amp;Test_A/ and Train&amp;Test_S/, example of panel anns and soiling fault anns.</p>
<p>Organize the dataset into 4 folders:</p>
<ul>
<li><p>train_image_folder &lt;= the folder that contains the train images.</p></li>
<li><p>train_annot_folder &lt;= the folder that contains the train annotations in VOC format.</p></li>
<li><p>valid_image_folder &lt;= the folder that contains the validation images.</p></li>
<li><p>valid_annot_folder &lt;= the folder that contains the validation annotations in VOC format.</p></li>
</ul>
<p>There is a one-to-one correspondence by file name between images and annotations.
For create own data set use LabelImg code from :
<a href="https://github.com/tzutalin/labelImg">https://github.com/tzutalin/labelImg</a></p>
<h4><a class="anchor" aria-hidden="true" id="2-edit-the-configuration-file"></a><a href="#2-edit-the-configuration-file" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>2. Edit the configuration file</h4>
<p>The configuration file for YOLO3 is a json file, which looks like this  (example soiling fault ):</p>
<pre><code class="hljs css language-javascript">{
  <span class="hljs-string">"model"</span> : {
    <span class="hljs-string">"min_input_size"</span>: <span class="hljs-number">400</span>,
    <span class="hljs-string">"max_input_size"</span>: <span class="hljs-number">400</span>,
    <span class="hljs-string">"anchors"</span>: [<span class="hljs-number">5</span>,<span class="hljs-number">7</span>, <span class="hljs-number">10</span>,<span class="hljs-number">14</span>, <span class="hljs-number">15</span>, <span class="hljs-number">15</span>, <span class="hljs-number">26</span>,<span class="hljs-number">32</span>, <span class="hljs-number">45</span>,<span class="hljs-number">119</span>, <span class="hljs-number">54</span>,<span class="hljs-number">18</span>, <span class="hljs-number">94</span>,<span class="hljs-number">59</span>, <span class="hljs-number">109</span>,<span class="hljs-number">183</span>, <span class="hljs-number">200</span>,<span class="hljs-number">21</span>],
    <span class="hljs-string">"labels"</span>: [<span class="hljs-string">"1"</span>],
    <span class="hljs-string">"backend"</span>: <span class="hljs-string">"full_yolo_backend.h5"</span>
  },
  <span class="hljs-string">"train"</span>: {
    <span class="hljs-string">"train_image_folder"</span>: <span class="hljs-string">"../Train&amp;Test_S/Train/images/"</span>,
    <span class="hljs-string">"train_annot_folder"</span>: <span class="hljs-string">"../Train&amp;Test_S/Train/anns/"</span>,
    <span class="hljs-string">"cache_name"</span>: <span class="hljs-string">"../Experimento_fault_1/Resultados_yolo3/full_yolo/experimento_fault_1_gpu.pkl"</span>,
    <span class="hljs-string">"train_times"</span>: <span class="hljs-number">1</span>,
    <span class="hljs-string">"batch_size"</span>: <span class="hljs-number">2</span>,
    <span class="hljs-string">"learning_rate"</span>: <span class="hljs-number">1e-4</span>,
    <span class="hljs-string">"nb_epochs"</span>: <span class="hljs-number">200</span>,
    <span class="hljs-string">"warmup_epochs"</span>: <span class="hljs-number">15</span>,
    <span class="hljs-string">"ignore_thresh"</span>: <span class="hljs-number">0.5</span>,
    <span class="hljs-string">"gpus"</span>: <span class="hljs-string">"0,1"</span>,
    <span class="hljs-string">"grid_scales"</span>: [<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>],
    <span class="hljs-string">"obj_scale"</span>: <span class="hljs-number">5</span>,
    <span class="hljs-string">"noobj_scale"</span>: <span class="hljs-number">1</span>,
    <span class="hljs-string">"xywh_scale"</span>: <span class="hljs-number">1</span>,
    <span class="hljs-string">"class_scale"</span>: <span class="hljs-number">1</span>,
    <span class="hljs-string">"tensorboard_dir"</span>: <span class="hljs-string">"log_experimento_fault_gpu"</span>,
    <span class="hljs-string">"saved_weights_name"</span>: <span class="hljs-string">"../Experimento_fault_1/Resultados_yolo3/full_yolo/experimento_yolo3_full_fault.h5"</span>,
    <span class="hljs-string">"debug"</span>: <span class="hljs-literal">true</span>
  },
  <span class="hljs-string">"valid"</span>: {
    <span class="hljs-string">"valid_image_folder"</span>: <span class="hljs-string">"../Train&amp;Test_S/Test/images/"</span>,
    <span class="hljs-string">"valid_annot_folder"</span>: <span class="hljs-string">"../Train&amp;Test_S/Test/anns/"</span>,
    <span class="hljs-string">"cache_name"</span>: <span class="hljs-string">"../Experimento_fault_1/Resultados_yolo3/full_yolo/val_fault_1.pkl"</span>,
    <span class="hljs-string">"valid_times"</span>: <span class="hljs-number">1</span>
  },
  <span class="hljs-string">"test"</span>: {
    <span class="hljs-string">"test_image_folder"</span>: <span class="hljs-string">"../Train&amp;Test_S/Test/images/"</span>,
    <span class="hljs-string">"test_annot_folder"</span>: <span class="hljs-string">"../Train&amp;Test_S/Test/anns/"</span>,
    <span class="hljs-string">"cache_name"</span>: <span class="hljs-string">"../Experimento_fault_1/Resultados_yolo3/full_yolo/test_fault_1.pkl"</span>,
    <span class="hljs-string">"test_times"</span>: <span class="hljs-number">1</span>
  }
}
</code></pre>
<p>The configuration file for SSD300 is a json file, which looks like this  (example soiling fault ) and .txt with name of images (train.txt):</p>
<pre><code class="hljs css language-javascript">{
  <span class="hljs-string">"model"</span> : {
    <span class="hljs-string">"backend"</span>: <span class="hljs-string">"ssd300"</span>,
    <span class="hljs-string">"input"</span>: <span class="hljs-number">400</span>,
    <span class="hljs-string">"labels"</span>: [<span class="hljs-string">"1"</span>]
  },
  <span class="hljs-string">"train"</span>: {
    <span class="hljs-string">"train_image_folder"</span>: <span class="hljs-string">"Train&amp;Test_S/Train/images"</span>,
    <span class="hljs-string">"train_annot_folder"</span>: <span class="hljs-string">"Train&amp;Test_S/Train/anns"</span>,
    <span class="hljs-string">"train_image_set_filename"</span>: <span class="hljs-string">"Train&amp;Test_S/Train/train.txt"</span>,
    <span class="hljs-string">"train_times"</span>: <span class="hljs-number">1</span>,
    <span class="hljs-string">"batch_size"</span>: <span class="hljs-number">12</span>,
    <span class="hljs-string">"learning_rate"</span>: <span class="hljs-number">1e-4</span>,
    <span class="hljs-string">"warmup_epochs"</span>: <span class="hljs-number">3</span>,
    <span class="hljs-string">"nb_epochs"</span>: <span class="hljs-number">100</span>,
    <span class="hljs-string">"saved_weights_name"</span>: <span class="hljs-string">"Result_ssd300_fault_1/experimento_ssd300_fault_1.h5"</span>,
    <span class="hljs-string">"debug"</span>: <span class="hljs-literal">true</span>
  },
  <span class="hljs-string">"valid"</span>: {
    <span class="hljs-string">"valid_image_folder"</span>: <span class="hljs-string">"../Train&amp;Test_D/Test/images/"</span>,
    <span class="hljs-string">"valid_annot_folder"</span>: <span class="hljs-string">"../Train&amp;Test_D/Test/anns/"</span>,
    <span class="hljs-string">"valid_image_set_filename"</span>: <span class="hljs-string">"../Train&amp;Test_D/Test/test.txt"</span>
  },
  <span class="hljs-string">"test"</span>: {
    <span class="hljs-string">"test_image_folder"</span>: <span class="hljs-string">"Train&amp;Test_S/Test/images"</span>,
    <span class="hljs-string">"test_annot_folder"</span>: <span class="hljs-string">"Train&amp;Test_S/Test/anns"</span>,
    <span class="hljs-string">"test_image_set_filename"</span>: <span class="hljs-string">"Train&amp;Test_S/Test/test.txt"</span>
  }
}
</code></pre>
<h4><a class="anchor" aria-hidden="true" id="3-start-the-training-process"></a><a href="#3-start-the-training-process" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>3. Start the training process</h4>
<p><code>python train_ssd.py -c config.json -o /path/to/result</code></p>
<p>or
<code>python train_ssd.py -c config.json -o /path/to/result</code></p>
<p>By the end of this process, the code will write the weights of the best model to file best_weights.h5 (or whatever name specified in the setting &quot;saved_weights_name&quot; in the config.json file). The training process stops when the loss on the validation set is not improved in 20 consecutive epoches.</p>
<h4><a class="anchor" aria-hidden="true" id="4-perform-detection-using-trained-weights-on-image-set-of-images"></a><a href="#4-perform-detection-using-trained-weights-on-image-set-of-images" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>4. Perform detection using trained weights on image, set of images</h4>
<p><code>python predict_ssd.py -c config.json -i /path/to/image/or/video -o /path/output/result</code>
or
<code>python predict_yolo.py -c config.json -i /path/to/image/or/video -o /path/output/result</code></p>
<p>It carries out detection on the image and write the image with detected bounding boxes to the same folder.</p>
<h3><a class="anchor" aria-hidden="true" id="evaluation"></a><a href="#evaluation" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Evaluation</h3>
<p>The evaluation is integrated into the training process, if you want to do the independent evaluation you must go to the folder ssd_keras-master or keras-yolo3-master and use the following code</p>
<p><code>python evaluate.py -c config.json</code></p>
<p>Compute the mAP performance of the model defined in <code>saved_weights_name</code> on the validation dataset defined in <code>valid_image_folder</code> and <code>valid_annot_folder</code>.</p>
<h3><a class="anchor" aria-hidden="true" id="weights-of-trained-models"></a><a href="#weights-of-trained-models" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Weights of Trained Models</h3>
<p>All of weights of this trained model grab from <a href="https://drive.google.com/drive/folders/1LSc9FkAwJrAAT8pAUWz8aax_biFAMMXS?usp=sharing">Drive_Weights</a></p>
<table>
<thead>
<tr><th style="text-align:center">Model</th><th style="text-align:center">Weights Trained</th><th style="text-align:center">Config</th></tr>
</thead>
<tbody>
<tr><td style="text-align:center">SSD7 Panel</td><td style="text-align:center"><a href="https://drive.google.com/open?id=1qNjfAp9sW1VJh8ewnb3NKuafhZockTqV">weight</a></td><td style="text-align:center"><a href="https://github.com/RentadroneCL/model-definition/blob/master/Result_ssd7_panel/config_7_panel.json">config</a></td></tr>
<tr><td style="text-align:center">SSD300 Soiling</td><td style="text-align:center"><a href="https://drive.google.com/open?id=1IiOyYW8yPAh4IALbM_ZVqRhLdxV-ZSPw">weight</a></td><td style="text-align:center"><a href="https://github.com/RentadroneCL/model-definition/blob/master/config_300_fault_1.json">config</a></td></tr>
<tr><td style="text-align:center">YOLO3 Panel</td><td style="text-align:center"><a href="https://drive.google.com/open?id=14zgtgDJv3KTvhRC-VOz6sqsGPC_bdrL1">weight</a></td><td style="text-align:center"><a href="https://github.com/RentadroneCL/model-definition/blob/master/config_full_yolo_panel_infer.json">config</a></td></tr>
<tr><td style="text-align:center">YOLO3 Soiling</td><td style="text-align:center"><a href="https://drive.google.com/open?id=1YLgkn1wL5xAGOpwd2gzdfsJVGYPzszn-">weight</a></td><td style="text-align:center"><a href="https://github.com/RentadroneCL/model-definition/blob/master/config_full_yolo_fault_1_infer.json">config</a></td></tr>
<tr><td style="text-align:center">YOLO3 Diode</td><td style="text-align:center"><a href="https://drive.google.com/open?id=1VUtrK9JVTbzBw5dX7_dgLTMToFHbAJl1">weight</a></td><td style="text-align:center"><a href="https://github.com/RentadroneCL/model-definition/blob/master/config_full_yolo_fault_4_infer.json">config</a></td></tr>
<tr><td style="text-align:center">YOLO3 Affected Cell</td><td style="text-align:center"><a href="https://drive.google.com/open?id=1ngyCzw7xF0N5oZnF29EIS5LOl1PFkRRM">weight</a></td><td style="text-align:center"><a href="https://github.com/RentadroneCL/model-definition/blob/master/config_full_yolo_fault_2_infer.json">config</a></td></tr>
</tbody>
</table>
<p>The image used are specified in <a href="https://github.com/RentadroneCL/model-definition/blob/master/Training_Images.xlsx">Table images</a>.
You can see some examples in <a href="https://github.com/RentadroneCL/model-definition/blob/master/README_Result.md">Summary of results</a>.</p>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/docs/developers"><span class="arrow-prev">← </span><span>Developers</span></a><a class="docs-next button" href="/docs/deployment"><span>Models Deployment</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#quickstart">Quickstart</a><ul class="toc-headings"><li><a href="#example-to-use-trained-model">Example to use trained model</a></li><li><a href="#model-detection">Model Detection</a></li><li><a href="#type-of-data">Type of Data</a></li><li><a href="#training">Training</a></li><li><a href="#evaluation">Evaluation</a></li><li><a href="#weights-of-trained-models">Weights of Trained Models</a></li></ul></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/" class="nav-home"><img src="/img/favicon.ico" alt="Rentadrone.cl" width="66" height="58"/></a><div><h5>Docs</h5><a href="/docs/en/developers">Getting Started</a></div><div><h5>Community</h5><a href="https://stackoverflow.com/questions/tagged/" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://discordapp.com/">Project Chat</a><a href="https://twitter.com/" target="_blank" rel="noreferrer noopener">Twitter</a></div><div><h5>More</h5><a href="https://github.com/RentadroneCL">GitHub</a></div></section><section class="copyright">Copyright © 2020 rentadrone.cl</section></footer></div></body></html>